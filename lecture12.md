# Machine Learning Algorithms 

----------------------------------------------------------

## 1장 [신경망이란 무엇인가?](https://www.youtube.com/watch?v=aircAruvnKk)
  - Speaker: 3Blue1Brown
  - 19:13 (조회 4.4 million)
  - 기계학습을 엔진은 뉴론과 뉴론으로 구성된 다층 인공신경망(neural network)을 다양한 방법과 구조로 사용합니다. 탁월한 시각적 효과를 사용하여 뉴론과 인공 신경망의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 한국어 자막
  - 요약
  - 서로 다른 픽셀과 패턴을 가진 숫자3을 우리는 3으로 인식하는데 뇌는 대체 어떻게 이런 어마어마한 일을 간단히 해내는 것일까? 기계학습과 신경망이 중요하다. 이번 강의는 신경망이 어떻게 돌아가는지 수학적으로 알게된다. 신경망의 구조에 대해서 알아보면 많은 구조가 존재한다. 제일 기본적인 신경망 형태가 있는데 꽤 복잡하다. 신경망은 더 세분화하면 뉴런이란게 있다 . 뉴런은 하나의 수를 담는 변수다 .0.0에서 1.0까지의 수 중에서 말이다. 각 뉴런은 컴퓨터에서 각 픽셀의 밝기를 나타내고 검은것은 0.0 밝은 것은 1.0이다. 각 뉴런은 활성치가 높을때 더욱 밝아진다. 이런 것들이 모여 신경망의 첫번째 층을 이루게 되고 마지막 레이어는 주어진 이미지가 가질 확률을 나타낸다. 그리고 그 사이의 레이어 들이 히든레이어라고 불린다. 정보 매커니즘에 있어 매우 중요한것은  어떻게 한층의 활성화가 다른 층의 활성화를 야기하는 것이냐는 것이다. 가운데 레이어는 무엇일까 . 우리는 숫자를 인식할때에 부분적으로 인식을 하는데 여러 직선으로 이루어진것을 힙쳐서 계산하는데 이 것이 마지막의 두번째 층에 집계된다. 그리고 마지막의 아웃풋을 선택하는 것이다. 즉 이미지가 들어왔을때 수많은 조각들로 활성화가 되고 이런 활성화된 뉴련이 다음층에 전달을 하게된다. 이 과정에서 가중치를 주게 된다. 가중치는 음수와 양수로 이루어진 가중치 중에 픽셀의 밝기에 따른 가중치들을 제외하여 한 부분의 픽셀에만 가중치를 주게된다. 그리고 가중를 준 값의 합은 0과 1 사이의 값이 되어야한다. 그래서 그렇게 만들어 주는 함수에 넣어주게 되고, 로지스틱함수로 알려진 시그모이드 함수에 넣게된다. 매우작은 음수는 0게 가깝게 되고 매우 큰 양수는 1에 가깝게된다. 0주위에서는 계속 늘어나게 된다. 그럼 어떻게 positive를 정하게 될까? 가중치의 값이 특정값의 이상이거나 이하일때를 정하게 bias 를 지정해준다. bias가 각 뉴런에 적용하고 이는 웨이트의 수와 바이어스의 수가 같다. 학습이란 올바른 가중치와 바이어스를 찾는다. 엣지를 찾아내고, 패턴을 찾아낸다. 그리고 마지막레이어의 뉴런을 선택한다. 각 계층의 활성화는 weight 값과 이전계층의 곱들의 합과 bias 합에 의해 결정된다.그리고 시그모이드나 Relu 함수를 취하게 된다.
  
## 2장 [경사하강, 신경망이 학습하는 방법](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2)
  - 3Blue1Brown
  - 21:01 (조회 1.7 million)
  - 경사하강법에 사용하는 비용함수에 대한 미분과 그 이유,경사하강법(Gradient Descent)의 작동 원리를 설명하고, 이를 이용하여 다층 인공신경망이 어떻게 학습을 하는지 설명합니다.  
  의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 한국어 자막
  - 요약
  - 이 영상은 경사하강법과 이 특별한 네트워크가 어떻게 동작하는지 알게된다.
예제에서 마지막계층에서 가장밝은 10개의 뉴런 중 하나를  숫자와 대응하는데 아마도 예제의 두번째 레이어는 숫자의 부분들, 그리고 세번째 레이어는 고리와 직선패턴을 찾아낼 것이다. 그리고 마지막 레이어는 저런 패턴을 조합하여 숫자를 인식한다. 우리가 원하는 것은 이런 학습이 이 네트워크를 학습 데이터 다발로 보여줄 수 있는 알고리즘인데 그것은 자필 자릿수의 다른 이미지의 묶음의 형태로 그들이 무엇을 해야하지는에 대한 레이블과 함꼐 제공이된다. 따라서 예제에서는 13,000개의 가중치 및 바이어스를 사용하여 교육 데이터의 성능을 향상시킬것이다. 기본적으로 특정 기능의 최소값을 찾는데 미적분을 이용한다. 각 쓰레기 출력 활성화 및 원하는 값 이것이 우리가 하나의 훈련에 드는 비용이다. 따라서 평균 비용을 고려해야한다. 이 평균 비용은 네트워크가 얼마나 나쁘고 컴퓨터가 얼마나 나빠야 하는지에 대한 우리의 측정이다.  함수의 최소값을 어떻게 찾을 수 있을 까 ? 최소값을 찾을 때에 복잡한 경우 방향을 정해야 하는데 이때 함수의 기울기를 통해 양수이면 왼쪽으로 이동하고 기울기가 음수이면 오른쪽으로 시프트하게 된다. 새로운 점을 확인하고 적절한 단계를 밟을 때마다 반복적으로 이 작접을 수행하면 치소값에 도달할 수 있게 된다. 그레디언트 백터의 길이는 실제로 가장 가파른 경사가 얼마나 가파른지에 대한 표시이다. 함수를 최소화하는 알고리즘은 이 기울기 방향을 계산한 다음 내리막 길을 약간 내리는 것이므로 반복해서 반복해서 한다. 효과적으로 신경망을 학습하는 방법의 핵심인 기울기를효과적으로 계산하고 알고리즘을 역전파 라고 한다. 예제에서 네거티브 그래디언트의 배수로 함수의 입력을 반복적으로 전환하는 이 프로세스를 그라디언트 디센트라고 한다. 기본적으로 비용함수의 지역 최소값으로 수렴하는 방법이다. 그래프의 골짜기이다. 음수그래디언트의 거대한 비용함수는 각 무게와 편향의 상대적 중요성을 인코딩 하는 것이다. 

## 3장 Optional [역전파 What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U&index=3&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
  - Speaker: 3Blue1Brown
  - 13:54 (조회 1.1 million)
  인공신경망 알고리즘의 핵심은 역전파(backpropagation) 알고리즘인데, 이 역전파의 원리를 탁월한 시각적 효과를 사용하여 설명합니다.
  의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 영어 자막
  - 요약
  - 신경망이 학습하는대한 핵심 알고리즘인 역전파에 대해 알아보자. 직관적인 이해를 돕는다. 오차에 관한 한가지 학습데이터를 살펴보면 우리가 해야할 것은 신경망이 출력한것과 신경망이 출력하길 원했던 값의 차이를 구한 후 모두 더한다 . 이걸 수천가지의 학습 데이터에 대해 수행하고 평균을 구하면 신경망의 모든 오차를 구할 수 있다. 우리가 찾고있는 것은 이 오차 함수의 음의 기울기인데 이것은 모든 가중치와 편향, 이 모든 연결을 어떻게 변경해야 하는지 알려준다. 이러한 방식으로 가장 효율적으로 오차함수를 줄일 수 있다. 역전파는 그 많은 복잡한 기울기를 계산하기 위한 알고리즘이다. 지난 예제에서 13,002 차원의 방향으로 생각하는 것은 우리가 상상할 수 있는 범위를 넘어선 것인데 그것에 대해서 다른 방법을 생각할 수 있다. 각 오차는 오차함수가 각 가중치 및 편차에 얼마나 민감한지를 나타낸다고 생각하는 것이다. 예를 들어, 한가지의 학습사례가 가중치와 편향을 조정하는 방법에 어떻게 영향을 미칠까를 생각해보면 훈련이 덜 된 네트워크에서 결과값은 무작위 처럼 보이지만  출력층의 어떤 값이 조정되어야 될지 아는것은 유용하다. 특정 원하는 이미지 결과를 제와하고 다 값을 내리면 된다. 근데 이때에 얼마큼 조정할것인지는 중요하다. 우리는 오차함수를 줄이는 것에 관심을 둔다. 뉴런의 활성화를 증가시킬 수있는 방법 중 세번째 방법은 이전 계층의 활성화를 모두 변경하는 것이다 즉 예제에서 찾고자 하는 숫자와 연결된 모든 양의 가중치 신경을 밝아지는 것이다.  이러한 방법으로 역전파를 하게된다. 역전파를 하면서 학습데이터를 무작위로 섞은 다음 이를 전체 배치로 나눈다. 
역전파는 알고리즘이다. 하나의 훈련 예가 가중치와 편향을 조금씩 움직이기를 원하는 지를 결정하기 위해 그들이 위 또는 아래로 가야하는지에 관해서뿐만아니라 그러나 그 변화에 대한 상대적인 비율이 비용을 가장빠르게 감소시키는 측면에서 볼때에 진정한 그래디언트 디센트 단계를 여러 교육 사례에 대해 작업을 수행해야한다. 그리고 얻는 원하는 변화를 평균화 시키는 것이다. 그러나 계산이 느리기 때문에   데이터를 작은 배치로 무작위로 세분한다. 반복적으로 모든 미니배치를 검토하고 이러한 조정을 수행하면 비용함수의 지역 최소값으로 수렴을 하게되고 즉 네트워크가 교육 사례에서 실제로 잘 수행 될 것이다. 



# Quiz
----------------------------------------------------------


## 1장 [신경망이란 무엇인가?](https://www.youtube.com/watch?v=aircAruvnKk)
  - Speaker: 3Blue1Brown
  - 19:13 (조회 4.4 million)
  - 기계학습을 엔진은 뉴론과 뉴론으로 구성된 다층 인공신경망(neural network)을 다양한 방법과 구조로 사용합니다. 탁월한 시각적 효과를 사용하여 뉴론과 인공 신경망의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 한국어 자막
  - 
  **Question 1:**  다음 빈칸에 강연자가 언급한 말로 알맞은 것은? 
  
  신경망의 마지막 층은 이미지가 가질 _______을 나타낸다.

```

(1) 확률  (2) 가중치 (3) 구글링 (4) =분포
```

답 1번

  **Question 2:** 다음 중 강연의 내용으로 알맞은 것은?
  

```

(1) 뉴런은 여러 신경망으로 이루어져 있다.  (2) 각 뉴련은 활성치가 낮을때에 밝아진다. (3) 신경망에 이미지가 들어오면 하나의 이미지로 압축시킨다. (4) 가중치의 합은 0과 1 사이의 값이 되어야 한다.
```
답 4번 


## 2장 [경사하강, 신경망이 학습하는 방법](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2)
  - 3Blue1Brown
  - 21:01 (조회 1.7 million)
  - 경사하강법에 사용하는 비용함수에 대한 미분과 그 이유,경사하강법(Gradient Descent)의 작동 원리를 설명하고, 이를 이용하여 다층 인공신경망이 어떻게 학습을 하는지 설명합니다.  
  의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 한국어 자막
  
 -
  **Question 3:** 다음 중 강연의 내용으로 알맞은 것은?
  

```

(1) 함수의 최대값을 미적분을 통해 찾는다.  (2) 예제에서 함수의 방향은 기울기를 통해 양수이면 오른쪽, 음수이면 왼쪽으로 시프트 한다. (3) 함수를 최소화 하는 알고리즘은 반복해서한다.. (4) 그래디언트 디센트는 비용함수의 지역 최대값으로 수렴하는 방법이다.
```
답 3번 

## 3장 Optional [역전파 What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U&index=3&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
  - Speaker: 3Blue1Brown
  - 13:54 (조회 1.1 million)
  인공신경망 알고리즘의 핵심은 역전파(backpropagation) 알고리즘인데, 이 역전파의 원리를 탁월한 시각적 효과를 사용하여 설명합니다.
  의 원리를 쉽게 설명합니다. 특히 기계학습의 기초를 이야기할 때마다 사용하는 MNIST(엠니스트) Dataset를 사용하여 숫자를 분별하는 원리를 설명합니다.
  - 영어 + 영어 자막
  -
  
  **Question 4:**  다음 빈칸에 강연자가 언급한 말로 알맞은 것은? 
  
  ______는 그 많은 복잡한 기울기를 계산하기 위한 알고리즘이다.

```

(1) 바이스  (2) 비용함수 (3) 역전파 (4) 오차함수
```

답 3번

 **Question 5:**  다음 강연자가 강연에서 언급한 말로 알맞은 것은? 
  

```

(1) 복잡한 기울기 계산을 위해 13000여가지의 달하는 차원의 방향으로 생각하는 것은 효율적이다.  (2) 역전파를 할때에 원하는 변화를 평균화 시킬때 계산이 느리기때문에 데이터를 작은 배치로 무작위로 세분한다. (3) 한번의 조정으로만으로도 비용함수의 지역 최소값으로 수렴한다. (4)  역전파는 직관적 이해를 돕지않는다
```

답 2번
